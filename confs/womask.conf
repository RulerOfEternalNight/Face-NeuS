general {
    base_exp_dir = ./exp/CASE_NAME/womask_sphere
    recording = [
        ./,
        ./models
    ]
}

dataset {
    data_dir = ./public_data/CASE_NAME/
    render_cameras_name = cameras_sphere.npz
    object_cameras_name = cameras_sphere.npz
}

train {
    # ------------------------------------------------------------
    # Optimizer & schedule
    # ------------------------------------------------------------
    learning_rate = 5e-4
    learning_rate_alpha = 0.05
    end_iter = 100000

    batch_size = 512
    validate_resolution_level = 4
    warm_up_end = 5000
    anneal_end = 50000
    use_white_bkgd = True

    # ------------------------------------------------------------
    # Logging / checkpoints
    # ------------------------------------------------------------
    save_freq = 10000
    val_freq = 2500
    val_mesh_freq = 5000
    report_freq = 100

    # ------------------------------------------------------------
    # Standard NeuS losses
    # ------------------------------------------------------------
    igr_weight = 0.1
    mask_weight = 0.0

    # ============================================================
    # Landmark supervision (Strategy 1: min |SDF| along landmark rays)
    # ============================================================

    # Weight for landmark loss
    # Safe starting range: 0.005 – 0.02
    landmark_weight = 0.01

    # Start landmark supervision AFTER coarse geometry emerges
    # (important to avoid early instability)
    landmark_start_iter = 15000

    # How many landmark rays to sample per iteration
    # (10 ≈ one per landmark)
    landmark_rays_per_iter = 10

    # Number of samples along each landmark ray
    # (64 is a good balance of stability vs speed)
    landmark_samples = 64

    # Optional: explicitly specify landmark names
    # If commented out, ALL landmarks present in landmarks_2d.json are used
    #
    # landmark_names = [
    #     "nose_tip",
    #     "chin",
    #     "left_eye_outer",
    #     "left_eye_inner",
    #     "right_eye_inner",
    #     "right_eye_outer",
    #     "mouth_left",
    #     "mouth_right",
    #     "nose_left",
    #     "nose_right"
    # ]
}

model {
    nerf {
        D = 8,
        d_in = 4,
        d_in_view = 3,
        W = 256,
        multires = 10,
        multires_view = 4,
        output_ch = 4,
        skips=[4],
        use_viewdirs=True
    }

    sdf_network {
        d_out = 257
        d_in = 3
        d_hidden = 256
        n_layers = 8
        skip_in = [4]
        multires = 6
        bias = 0.5
        scale = 1.0
        geometric_init = True
        weight_norm = True
    }

    variance_network {
        init_val = 0.3
    }

    rendering_network {
        d_feature = 256
        mode = idr
        d_in = 9
        d_out = 3
        d_hidden = 256
        n_layers = 4
        weight_norm = True
        multires_view = 4
        squeeze_out = True
    }

    neus_renderer {
        n_samples = 64
        n_importance = 64
        n_outside = 32
        up_sample_steps = 4     # 1 for simple coarse-to-fine sampling
        perturb = 1.0
    }
}
